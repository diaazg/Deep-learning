{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3b4a97",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50795a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data  import DataLoader,TensorDataset\n",
    "import copy \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b859fe",
   "metadata": {},
   "source": [
    "# Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d1d5808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    0    1    2    3    4    5    6    7    8  ...  774  775  776  \\\n",
       "0      5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "   777  778  779  780  781  782  783  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/mnist_train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a387f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 784), (30000,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_train.values[:30000,1:]\n",
    "labels = df_train.values[:30000,0]\n",
    "data.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28eabf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNorm = data / np.max(data)\n",
    "dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)\n",
    "dataNorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "979ae1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = torch.tensor(dataNorm,dtype=torch.float32)\n",
    "labelsT = torch.tensor(labels,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5ad0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data , train_labels , test_labels = train_test_split(dataT,labelsT,test_size=.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "816d0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data = TensorDataset(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75c19128",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db52f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18000, 1, 28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8bbbd",
   "metadata": {},
   "source": [
    "# FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "634ea800",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(.5,.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0872a0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [01:40<00:00, 264kB/s] \n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 280kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:36<00:00, 120kB/s] \n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 967kB/s]\n"
     ]
    }
   ],
   "source": [
    "fmnist_train = torchvision.datasets.FashionMNIST(root='../data',train=True,download=True,transform=transform)\n",
    "fmnist_test = torchvision.datasets.FashionMNIST(root='../data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e9f6457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fmnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ff8584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_train_loader = DataLoader(fmnist_train,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "fmnist_test_loader =  DataLoader(fmnist_test,batch_size=len(fmnist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12e3de",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27da535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMnisNet(printtogle=False):\n",
    "    class MNISnet(nn.Module):\n",
    "        def __init__(self,printtogle):\n",
    "            super().__init__()\n",
    "             \n",
    "             # convolutional layers\n",
    "\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1, padding=1)\n",
    "            # out_channels represents the number of feature maps\n",
    "            # the output will be np.floor((28-5+2*1)/1) + 1 = 26 \n",
    "            # then we apply max pooling by spatial extent 2*2 so the output will be 26/2 = 13 \n",
    "            self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=1) \n",
    "            # output will be 13-5+2*1 = 11\n",
    "            # then we apply max pooling by spatial extent 2*2 so the output will be 11/2 = 5\n",
    "            # in this case we take the floor so the ceiling mode in the max pooling will be False since it give 5 not 6\n",
    "            \n",
    "            # Computer number of units in FC layer (number of output of conv2)\n",
    "            expectSize = np.floor((5+2*0-1)/1) + 1\n",
    "            expectSize = 20*int(expectSize**2)\n",
    "\n",
    "            ### fully connected layer\n",
    "            self.fc1 = nn.Linear(expectSize, 50)\n",
    "            self.out = nn.Linear(50, 10)\n",
    "            # togle for printing out our tensorsizes during forward pass\n",
    "            self.print = printtogle\n",
    "\n",
    "        def forward(self, x,doBN=False):\n",
    "            print(f'Input: {x.shape} ') if self.print else None\n",
    "\n",
    "            # convol -> maxpool -> relu\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "            print(f'Conv1/pool1: {x.shape} ') if self.print else None\n",
    "\n",
    "            x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "            print(f'Conv2/pool2: {x.shape} ') if self.print else None\n",
    "\n",
    "            nUnits  = x.shape.numel() / x.shape[0] # number of units \n",
    "            #we get it by dividing the total number of units by the batch size to get the number of units per image\n",
    "            x = x.view(-1,int(nUnits))\n",
    "            # -1 tells pytorch to infer the first dimension\n",
    "            # Reshape x to (batch_size, nUnits)\n",
    "            # we can do that x = x.view(x.shape[0], int(nUnits)) by -1 is automatically and well\n",
    "\n",
    "\n",
    "            print(f'Vectorized: {x.shape} ') if self.print else None\n",
    "\n",
    "            # Linear layers\n",
    "            x = F.relu(self.fc1(x))\n",
    "            print(f'FC1: {x.shape} ') if self.print else None\n",
    "\n",
    "            x = self.out(x)\n",
    "            print(f'Output: {x.shape} ') if self.print else None\n",
    "\n",
    "            return x\n",
    "\n",
    "    net = MNISnet(printtogle)\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=.005)\n",
    "    \n",
    "    \n",
    "    return net, lossfun, optimizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2ed3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../models')\n",
    "import importlib \n",
    "import training\n",
    "importlib.reload(training)\n",
    "from training import trainTheM0del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2599d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "model, lossfun, optimizer = createMnisNet(printtogle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5c3af67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41562e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.2443, Train Acc: 92.17, Test Acc: 96.17\n",
      "Epoch 2/20, Train Loss: 0.0814, Train Acc: 97.47, Test Acc: 97.14\n",
      "Epoch 3/20, Train Loss: 0.0625, Train Acc: 98.03, Test Acc: 97.74\n",
      "Epoch 4/20, Train Loss: 0.0460, Train Acc: 98.61, Test Acc: 97.54\n",
      "Epoch 5/20, Train Loss: 0.0382, Train Acc: 98.67, Test Acc: 97.98\n",
      "Epoch 6/20, Train Loss: 0.0411, Train Acc: 98.70, Test Acc: 98.05\n",
      "Epoch 7/20, Train Loss: 0.0300, Train Acc: 99.01, Test Acc: 97.90\n",
      "Epoch 8/20, Train Loss: 0.0321, Train Acc: 99.01, Test Acc: 97.87\n",
      "Epoch 9/20, Train Loss: 0.0326, Train Acc: 99.00, Test Acc: 97.60\n",
      "Epoch 10/20, Train Loss: 0.0233, Train Acc: 99.29, Test Acc: 98.18\n",
      "Epoch 11/20, Train Loss: 0.0262, Train Acc: 99.30, Test Acc: 97.91\n",
      "Epoch 12/20, Train Loss: 0.0255, Train Acc: 99.27, Test Acc: 97.96\n",
      "Epoch 13/20, Train Loss: 0.0292, Train Acc: 99.15, Test Acc: 97.73\n",
      "Epoch 14/20, Train Loss: 0.0253, Train Acc: 99.31, Test Acc: 97.79\n",
      "Epoch 15/20, Train Loss: 0.0209, Train Acc: 99.41, Test Acc: 98.37\n",
      "Epoch 16/20, Train Loss: 0.0325, Train Acc: 99.23, Test Acc: 98.08\n",
      "Epoch 17/20, Train Loss: 0.0210, Train Acc: 99.44, Test Acc: 97.93\n",
      "Epoch 18/20, Train Loss: 0.0332, Train Acc: 99.11, Test Acc: 97.01\n",
      "Epoch 19/20, Train Loss: 0.0182, Train Acc: 99.52, Test Acc: 98.25\n",
      "Epoch 20/20, Train Loss: 0.0159, Train Acc: 99.61, Test Acc: 97.73\n"
     ]
    }
   ],
   "source": [
    "losses, train_accuracy, test_accuracy = trainTheM0del(\n",
    "        isClassification=True,\n",
    "        optimizer = optimizer,\n",
    "        doBN=False,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        num_epochs=num_epochs, \n",
    "        loss_function= lossfun,\n",
    "        device = device\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3eaf93",
   "metadata": {},
   "source": [
    "# Fine-tune the MNIST model on FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b057ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "Parameter containing:\n",
      "tensor([[[[-2.4280e-01,  7.0474e-02,  1.0293e-01, -3.0825e-03, -1.9726e-01],\n",
      "          [-6.8802e-01, -4.0762e-01, -1.0186e-02, -3.1067e-01,  1.9792e-01],\n",
      "          [-8.4532e-01, -1.4128e-01, -2.8844e-01,  2.6224e-01,  3.5622e-01],\n",
      "          [-6.6717e-01, -1.6544e-01,  1.2890e-01,  4.6189e-01,  2.4482e-01],\n",
      "          [-2.5795e-01, -2.0679e-02, -1.5538e-01,  4.6556e-01,  2.7924e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4005e-02,  3.1989e-01,  1.8976e-01,  4.8423e-02,  1.7424e-01],\n",
      "          [ 2.1086e-03, -1.0800e-01, -3.2814e-01, -2.8427e-01, -1.1542e-01],\n",
      "          [-2.2748e-01, -8.4293e-01, -5.6044e-01,  3.0844e-01,  2.8362e-01],\n",
      "          [ 3.5503e-02, -5.2392e-01,  2.2155e-01,  6.5860e-01,  1.5974e-01],\n",
      "          [-5.6431e-02,  3.6196e-01,  4.1099e-01,  3.6693e-01, -4.3148e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1497e-01,  4.1667e-01,  3.7679e-01,  4.7430e-01, -7.8030e-02],\n",
      "          [-1.9697e-01,  1.2160e-01,  1.6314e-01, -1.0936e-02, -2.9331e-01],\n",
      "          [-2.0306e-01, -2.7580e-01,  2.9229e-01, -2.6950e-01, -7.3609e-01],\n",
      "          [ 1.4127e-01, -6.2942e-01, -1.1917e+00, -1.3591e+00, -5.6274e-01],\n",
      "          [-3.5320e-02, -4.8370e-01, -9.3558e-01, -2.0642e-02,  1.3134e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3296e-01, -8.2052e-02, -2.5530e-01, -1.5640e-01,  1.2811e-01],\n",
      "          [ 2.2628e-01, -1.5060e-01, -5.1774e-01, -3.0362e-01,  3.0269e-01],\n",
      "          [ 2.5282e-01, -4.3216e-01, -8.1032e-01, -1.1362e-01,  2.2188e-01],\n",
      "          [ 1.2391e-03, -6.4246e-01, -1.6070e-01,  8.4684e-02,  4.2991e-01],\n",
      "          [-2.8054e-01, -2.1872e-01, -3.7991e-01,  1.7235e-01,  1.7523e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7132e-01,  1.0583e-01,  3.0534e-01,  2.7639e-01,  4.4781e-02],\n",
      "          [ 1.1812e-01,  8.5903e-02,  2.5640e-01,  4.2400e-01,  3.4025e-01],\n",
      "          [-4.2455e-01,  6.0108e-02, -6.4361e-02, -1.2354e-01,  4.6082e-02],\n",
      "          [-7.2486e-01, -9.2753e-01, -9.1909e-01, -6.1071e-01,  2.0385e-02],\n",
      "          [ 1.1563e-01,  1.0751e-01, -1.4236e-01, -1.1560e-01, -1.0899e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7697e-01, -5.0739e-01, -4.8782e-01, -1.0200e+00, -9.0713e-01],\n",
      "          [-2.0807e-01, -3.1888e-01, -2.4403e-01,  4.1308e-01,  2.4094e-01],\n",
      "          [-1.2917e-02, -3.2016e-02,  1.3335e-01,  4.2150e-01,  3.0814e-01],\n",
      "          [ 1.3397e-01,  1.8076e-01, -2.0375e-01, -4.0516e-02, -5.8726e-02],\n",
      "          [-2.6407e-01, -7.4946e-01, -1.3691e+00, -3.8688e-01,  3.2996e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2032e-01,  2.0634e-01, -1.8492e-01, -3.4961e-01, -1.6087e-01],\n",
      "          [ 1.2283e-01,  2.1127e-01, -9.6540e-02, -4.1456e-01, -1.1028e-01],\n",
      "          [ 4.3289e-01,  1.4907e-01,  1.2999e-02, -7.4661e-02,  4.7609e-02],\n",
      "          [ 4.9293e-01,  1.9657e-01, -2.5098e-01, -4.5823e-01,  2.0430e-01],\n",
      "          [-1.3678e-01, -7.1994e-01, -1.2145e+00, -4.8777e-01, -1.8245e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1672e-01, -2.6444e-01, -2.8024e-01, -2.8366e-01,  2.0923e-01],\n",
      "          [ 1.3479e-01, -8.0304e-01, -4.7801e-01,  1.1290e-01,  3.1240e-01],\n",
      "          [-2.6994e-01, -3.6594e-01,  3.6484e-02,  7.2611e-01, -4.9990e-02],\n",
      "          [ 1.1145e-01,  1.8406e-01,  6.7741e-01, -1.5800e-01, -8.0522e-01],\n",
      "          [ 3.9582e-01,  7.1755e-02, -4.7626e-01, -9.8715e-01, -1.9358e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3345e-01, -2.1899e-01,  2.7289e-01,  4.9960e-01, -4.9451e-01],\n",
      "          [-7.7233e-02, -1.4834e-01,  1.5789e-01,  2.5808e-01, -1.4347e+00],\n",
      "          [-7.6331e-01, -2.6704e-01,  3.4079e-01,  8.7871e-01, -5.2746e-01],\n",
      "          [-7.3518e-01, -8.1222e-01,  1.6280e-01,  6.8837e-01,  8.0682e-02],\n",
      "          [-8.8635e-01, -5.3462e-01, -1.8882e-01,  1.1677e-01,  1.3399e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3061e-02, -1.6422e-01, -5.8950e-01, -1.0127e-01, -1.2566e-01],\n",
      "          [ 3.2455e-01, -3.5042e-02, -1.7189e-01, -5.0668e-01, -1.1142e+00],\n",
      "          [ 1.6069e-01,  5.1597e-01,  4.8236e-01, -1.3873e-01, -2.7959e-02],\n",
      "          [-2.9341e-02,  3.5640e-01,  5.8477e-01,  6.1756e-01,  2.1123e-01],\n",
      "          [-4.1854e-01, -2.8195e-01,  1.5240e-01,  9.5681e-02,  3.0695e-01]]]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "conv1.bias\n",
      "Parameter containing:\n",
      "tensor([-0.4446, -0.5539,  0.2042, -0.7708, -0.0342, -0.4561, -0.3655, -0.5792,\n",
      "        -0.2783, -0.4170], device='mps:0', requires_grad=True)\n",
      "conv2.weight\n",
      "Parameter containing:\n",
      "tensor([[[[-2.2409e-01,  1.6245e-01, -3.5678e-01, -9.9689e-01, -5.6772e-01],\n",
      "          [-1.3680e-02, -1.2765e-01, -1.2292e-01, -4.5233e-01, -5.9317e-01],\n",
      "          [-8.9034e-01, -1.3508e+00, -1.9732e-01,  8.1424e-02, -5.4985e-01],\n",
      "          [-3.4445e-01, -9.8122e-01, -4.7737e-01,  3.7162e-01,  7.9235e-02],\n",
      "          [-4.4804e-01, -3.5953e-01, -4.3464e-01,  5.8870e-01, -5.1420e-02]],\n",
      "\n",
      "         [[-2.2903e-01,  4.2388e-01,  1.8999e-01, -4.4329e-01, -2.0089e-01],\n",
      "          [ 2.9813e-01,  4.6206e-01, -4.5474e-01, -4.1465e-01, -1.6601e-01],\n",
      "          [-1.0720e+00, -1.3668e+00,  9.6523e-02, -1.4466e-01, -1.8893e-03],\n",
      "          [-1.1047e+00, -1.1130e+00, -5.3691e-01,  4.8754e-02, -1.3846e-01],\n",
      "          [-6.9808e-01, -7.8847e-01, -5.5034e-01,  6.0953e-01, -1.8846e-01]],\n",
      "\n",
      "         [[ 6.1496e-01, -2.2735e-01, -2.1442e-01,  2.8465e-01,  2.1280e-01],\n",
      "          [ 5.8544e-01, -6.0020e-01, -1.5884e+00, -1.0427e+00, -2.5328e-01],\n",
      "          [ 2.1320e-01,  2.9819e-01,  2.1852e-01,  1.7871e-01, -2.9611e-01],\n",
      "          [ 1.1426e-01,  8.7809e-02, -7.4278e-02, -2.6494e-01, -7.2449e-01],\n",
      "          [-3.4613e-01,  2.8049e-02, -3.1281e-01, -1.1124e+00, -1.4189e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8850e-01, -2.5569e-01,  4.7117e-01,  1.6109e-02, -1.1802e-01],\n",
      "          [-7.6850e-02,  3.8411e-01, -3.8039e-01,  1.4412e-01, -7.3079e-01],\n",
      "          [-5.9865e-01, -5.5188e-01, -5.0808e-01, -7.3440e-02, -3.5907e-01],\n",
      "          [-3.5593e-01, -5.8918e-01, -1.6202e-01, -3.0033e-01,  1.4351e-01],\n",
      "          [ 3.3851e-01, -5.6056e-01, -1.2580e+00, -5.5681e-01,  9.1382e-02]],\n",
      "\n",
      "         [[-5.7934e-01, -4.0653e-01, -5.8958e-01, -5.9082e-01, -5.2381e-01],\n",
      "          [ 4.9536e-01,  2.8505e-01,  7.3895e-01,  6.5191e-02, -2.5376e-01],\n",
      "          [-7.8575e-01,  3.6325e-01,  3.3370e-02,  2.8467e-01,  2.4826e-01],\n",
      "          [ 4.4973e-01, -2.0781e-01,  5.1326e-01,  1.3229e-01,  7.0916e-02],\n",
      "          [-2.1605e-01, -8.8807e-01, -5.8799e-01,  4.2364e-01,  1.7473e-01]],\n",
      "\n",
      "         [[-1.0281e-01, -1.4870e-01, -5.7378e-02, -1.0540e-01, -7.0855e-02],\n",
      "          [ 5.1514e-02,  2.6504e-01,  5.1453e-01,  3.1395e-01, -1.4813e-01],\n",
      "          [-2.2707e-01, -1.0647e-01,  1.0902e-01,  3.0786e-01,  1.3950e-01],\n",
      "          [-8.0019e-01, -8.5930e-01, -4.7080e-01,  8.0961e-02, -4.3326e-02],\n",
      "          [-8.1680e-01, -1.0108e+00, -3.4580e-01, -7.7532e-01, -4.3103e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0793e-01,  6.3162e-01,  1.6289e-01, -4.5872e-02, -6.5336e-01],\n",
      "          [-6.2304e-01,  5.7661e-01,  5.8487e-01, -3.1944e-01,  3.0906e-03],\n",
      "          [-3.4380e-01,  4.4330e-01,  5.5543e-01, -6.7885e-01, -1.3640e-02],\n",
      "          [-5.8625e-01,  1.5922e-01,  1.8810e-01,  2.1708e-01, -1.1063e+00],\n",
      "          [-7.4407e-01, -3.8031e-01,  1.4738e-01,  2.4728e-01, -7.1119e-01]],\n",
      "\n",
      "         [[-6.1909e-01,  2.1322e-01,  2.8384e-01,  6.2397e-01, -7.8548e-02],\n",
      "          [-4.3798e-01,  4.0184e-01,  3.3933e-01,  2.6368e-01,  4.2259e-01],\n",
      "          [-4.0490e-01,  2.9255e-01, -3.4211e-02, -7.9693e-01,  3.4652e-01],\n",
      "          [ 1.0659e-01,  3.7473e-01, -4.6856e-01, -1.2402e+00,  2.2489e-01],\n",
      "          [-2.4342e-01, -2.1690e-01, -1.6174e-01, -7.8736e-01, -9.3392e-01]],\n",
      "\n",
      "         [[-2.6820e-01, -2.9013e-01, -1.9088e-01,  1.2557e-01,  8.9990e-02],\n",
      "          [ 1.4929e-01, -7.9478e-01, -1.5527e+00, -3.5737e-01,  3.8422e-01],\n",
      "          [ 2.8555e-01, -1.2841e+00, -3.3370e+00, -1.2728e+00, -1.5544e-01],\n",
      "          [ 2.0573e-01, -7.2526e-01, -2.9095e+00, -1.3101e+00, -3.8712e-01],\n",
      "          [-4.7275e-02, -3.3901e-01, -4.1725e-01, -3.4269e-01,  3.6296e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2213e-01, -2.1131e-01, -1.0451e+00,  7.4830e-02,  1.1469e-01],\n",
      "          [-3.7040e-01,  5.0168e-02,  2.3132e-02,  5.1117e-01,  3.4918e-01],\n",
      "          [ 9.9035e-02, -3.3850e-01, -5.7718e-02, -2.7305e-01,  1.3958e-01],\n",
      "          [-1.4365e-01, -1.5116e-02, -2.5222e-02,  2.8443e-01,  8.8968e-01],\n",
      "          [ 2.0399e-01,  1.6685e-01, -9.0618e-01, -5.1298e-01,  6.3792e-01]],\n",
      "\n",
      "         [[-1.5589e-02,  7.0108e-01,  3.4403e-01, -5.3100e-01, -1.5747e-01],\n",
      "          [-1.0482e-01,  5.4934e-01,  4.1471e-01, -4.3907e-01, -4.4405e-01],\n",
      "          [ 1.4657e-01,  2.3682e-01,  1.9932e-01,  5.3439e-01, -1.8567e-01],\n",
      "          [ 7.3089e-01, -6.6755e-02,  1.3842e-01,  7.8744e-01, -6.1652e-01],\n",
      "          [ 1.0393e-01, -1.2983e+00, -2.6326e-01, -4.3206e-01, -2.2093e-01]],\n",
      "\n",
      "         [[-9.0557e-01, -9.6325e-01,  1.5152e-01,  3.5595e-01,  2.9248e-01],\n",
      "          [-1.4022e-01, -1.0856e+00,  1.9919e-01,  4.6506e-01,  3.7970e-01],\n",
      "          [ 2.5650e-02, -1.1638e+00, -7.2072e-01,  1.1974e-01, -1.5382e-01],\n",
      "          [ 4.5667e-01, -2.2453e-01, -3.3555e-01,  2.8887e-01,  3.0274e-01],\n",
      "          [ 4.4116e-01,  4.0234e-02, -5.4159e-02,  6.8811e-02,  3.3217e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.9088e-01, -4.5101e-01, -2.6428e-01,  5.0638e-02,  1.6385e-01],\n",
      "          [-1.0556e+00, -1.6075e-01,  5.5677e-01,  4.6145e-01,  2.5794e-01],\n",
      "          [-9.5816e-01, -8.7318e-01, -3.0573e-01, -5.1930e-03, -1.1542e-01],\n",
      "          [-2.0714e-01, -4.2616e-01, -5.9339e-01, -5.3723e-01, -2.0991e-01],\n",
      "          [ 4.4842e-01,  3.1815e-01,  3.5923e-01,  1.8694e-01,  1.5559e-01]],\n",
      "\n",
      "         [[-7.1802e-02, -1.0426e-01,  1.9422e-01,  5.0620e-01,  4.8920e-01],\n",
      "          [-4.6979e-01,  2.2728e-01,  4.3843e-01,  4.0593e-01,  2.8585e-01],\n",
      "          [-8.9725e-01, -6.4929e-01, -8.2404e-01, -1.3775e+00, -7.8853e-01],\n",
      "          [ 6.9233e-02, -6.4418e-03, -3.0774e-01, -1.8543e-01,  5.0335e-02],\n",
      "          [ 6.0199e-01,  2.9078e-01,  4.5280e-01,  4.7317e-01,  3.3453e-01]],\n",
      "\n",
      "         [[ 2.0111e-01,  1.1969e-01,  4.3763e-01,  1.7739e-01,  2.2008e-01],\n",
      "          [ 2.1001e-01,  6.2904e-02, -3.6485e-01, -6.1103e-01, -1.5690e+00],\n",
      "          [ 1.9679e-01, -6.1051e-01, -2.8787e-02,  1.6210e-01,  6.2299e-02],\n",
      "          [ 3.6184e-01,  1.6687e-01,  7.1521e-02,  2.0365e-01,  2.7622e-01],\n",
      "          [-5.8481e-01, -3.0970e-01, -1.5393e-01, -6.7438e-01, -7.8469e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.7227e-01,  5.5417e-01, -1.2794e-01, -5.5223e-02,  4.6012e-01],\n",
      "          [-1.6849e-03, -2.6936e-01,  3.5715e-01, -6.4255e-01,  1.5584e-01],\n",
      "          [ 5.6036e-02,  2.4431e-01, -1.6609e-01, -1.0653e+00, -6.2643e-01],\n",
      "          [-3.0705e-01, -1.9978e-01, -9.0177e-01, -3.0301e-01, -1.5890e-01],\n",
      "          [ 1.9544e-01, -3.9682e-01, -2.4703e-02,  8.9579e-02,  1.5384e-01]],\n",
      "\n",
      "         [[ 1.2432e-01, -4.9048e-02, -2.2881e-01, -8.1718e-01, -3.1291e-01],\n",
      "          [-6.6595e-01,  1.6143e-01,  3.1255e-01,  2.2341e-01,  2.7616e-01],\n",
      "          [-3.4244e-01,  3.9352e-01,  1.0888e-01, -4.0174e-02,  6.5133e-01],\n",
      "          [ 8.5571e-02, -2.0536e-01, -1.6744e-01, -3.0815e-01, -4.6289e-01],\n",
      "          [ 1.9732e-01,  2.9125e-01,  8.1469e-02, -5.6014e-01, -1.0719e+00]],\n",
      "\n",
      "         [[-8.5875e-01, -6.2485e-01, -4.9624e-01, -9.9947e-02, -5.7431e-01],\n",
      "          [-5.6727e-01, -2.0612e-01, -1.9966e-01, -5.2002e-02,  1.7604e-01],\n",
      "          [ 1.9529e-01,  3.7539e-01,  2.4803e-02, -8.1870e-01, -4.0737e-02],\n",
      "          [-5.3033e-01,  9.7447e-02,  2.6498e-01, -1.9869e-01, -1.5386e+00],\n",
      "          [ 2.6698e-01,  8.7742e-02,  4.4498e-01,  3.0769e-01,  1.5014e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.9842e-01, -3.6741e-02, -4.3845e-01,  7.4697e-01,  4.5194e-01],\n",
      "          [-2.3990e-01, -1.3682e-01, -7.7779e-01, -1.0069e+00, -3.5388e-01],\n",
      "          [ 2.0911e-01,  1.9069e-01, -4.6880e-01, -3.5314e-01,  4.5712e-01],\n",
      "          [ 4.2688e-01,  4.2638e-01,  3.7743e-01, -2.6591e-01,  4.8288e-03],\n",
      "          [-6.1205e-02, -3.6244e-01, -2.6928e-01, -3.4017e-01, -3.4933e-01]],\n",
      "\n",
      "         [[ 2.8523e-01, -1.3017e-01, -2.9139e-01, -2.8022e-01, -2.7629e-01],\n",
      "          [-3.8618e-01, -2.9657e-01, -6.6378e-02, -4.4453e-01, -5.4302e-01],\n",
      "          [ 2.1891e-01, -3.3440e-01, -1.8666e-01, -5.0110e-01,  2.1279e-01],\n",
      "          [ 6.3629e-01, -1.2999e-01, -2.0796e-01, -4.0994e-02,  2.3472e-02],\n",
      "          [ 4.3545e-01,  1.9112e-01, -7.3421e-02, -5.4703e-01, -1.2812e+00]],\n",
      "\n",
      "         [[ 1.1848e-01,  4.1683e-01,  5.8747e-01, -5.5221e-02,  2.2073e-01],\n",
      "          [-6.2768e-01, -7.0084e-01, -1.6754e-01, -1.4376e-01,  2.0293e-01],\n",
      "          [-1.9456e-01, -1.2434e+00, -1.1756e+00, -1.3381e-01,  1.1888e-01],\n",
      "          [-4.1786e-01, -1.9553e-01, -7.4921e-01, -9.8698e-01, -4.0002e-02],\n",
      "          [ 3.3279e-01,  3.7883e-01,  1.8949e-02, -2.1312e-01,  4.3213e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8398e-01,  2.7108e-01,  2.5957e-02, -9.7062e-01,  3.0764e-01],\n",
      "          [-2.7879e-01, -3.8133e-01, -1.8634e-01, -3.8017e-01, -1.0329e+00],\n",
      "          [ 7.8274e-03, -4.6501e-01, -1.7651e-01,  1.2014e-01,  3.9298e-02],\n",
      "          [ 2.9672e-01, -4.1529e-01, -6.3154e-01,  1.2402e-01,  5.0826e-01],\n",
      "          [ 8.6822e-01,  4.0822e-01, -5.4132e-01, -2.9646e-02,  1.2921e-01]],\n",
      "\n",
      "         [[-6.6555e-01, -1.1130e+00, -5.2358e-01,  4.6995e-01, -2.6890e-01],\n",
      "          [ 2.3688e-01, -1.8517e-01, -4.6655e-01, -2.2746e-01, -2.5996e-01],\n",
      "          [ 1.1652e-01,  1.5004e-01,  4.5530e-01,  1.2937e-01,  1.1560e+00],\n",
      "          [ 4.1017e-02,  5.7794e-01,  1.2697e-01,  1.9256e-01,  5.5158e-02],\n",
      "          [-3.5869e-01, -5.6648e-01, -3.1356e-01,  5.0498e-01, -9.2847e-01]],\n",
      "\n",
      "         [[ 9.7404e-01, -6.7595e-01, -1.6087e+00, -8.4134e-01, -1.3493e-01],\n",
      "          [ 6.7950e-01,  7.9936e-01,  2.8228e-01, -8.7121e-02, -1.3350e+00],\n",
      "          [-6.0768e-01,  1.5739e-01,  3.9915e-01,  2.2244e-01,  4.5588e-01],\n",
      "          [-1.1068e+00, -6.0950e-01, -2.7897e-01,  6.0464e-02,  4.3565e-02],\n",
      "          [-6.4789e-01, -8.0510e-01, -7.8459e-01, -8.4509e-02,  1.6637e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7979e-02, -3.8921e-02, -1.9228e-01, -3.4866e-01, -1.4622e-01],\n",
      "          [-2.7780e-01, -2.9606e-02, -1.6704e-02, -4.0177e-01, -2.1780e-01],\n",
      "          [-2.4491e-01, -5.0705e-02, -8.9711e-02, -3.5488e-01, -1.9481e-01],\n",
      "          [-1.9441e-01, -1.2730e-01, -6.5406e-02, -2.4547e-01, -4.5748e-02],\n",
      "          [-1.0343e-01, -1.1197e-01, -2.8352e-02,  7.9125e-02, -1.2926e-02]],\n",
      "\n",
      "         [[ 5.4997e-03,  1.6197e-01, -7.9217e-02, -2.2462e-01, -2.6070e-01],\n",
      "          [-2.3902e-01,  9.3164e-02, -9.0128e-02, -3.5984e-01, -2.4169e-01],\n",
      "          [-8.3387e-02, -3.7591e-02, -1.2072e-01, -3.8222e-01, -3.5347e-01],\n",
      "          [-2.4187e-01, -2.2717e-01, -6.7734e-02, -3.1861e-01, -1.0311e-01],\n",
      "          [-2.0544e-01, -1.5930e-01,  1.8972e-02,  7.7824e-02, -6.5450e-02]],\n",
      "\n",
      "         [[-3.2139e-01, -1.9615e-01, -1.5453e-01, -3.6896e-01, -2.3658e-01],\n",
      "          [-1.7911e-01, -1.7421e-01, -2.0284e-01, -2.0007e-01, -2.9936e-01],\n",
      "          [-1.2849e-01, -2.6093e-01, -1.7700e-01, -1.1737e-01, -2.4611e-01],\n",
      "          [-1.1465e-01, -1.7821e-01, -2.1743e-01, -1.4260e-01, -2.1160e-01],\n",
      "          [-8.6746e-02, -2.2633e-01, -2.3692e-01, -2.1091e-01, -3.1010e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.4677e-02, -7.9922e-03, -2.1595e-01,  2.1562e-01, -1.0117e-01],\n",
      "          [ 1.9705e-01,  1.4915e-01, -1.7672e-01, -1.1792e-01,  2.7187e-02],\n",
      "          [ 1.4271e-01, -1.9138e-01, -9.6097e-02, -3.1219e-01, -8.3695e-02],\n",
      "          [-3.1571e-02, -1.6494e-01, -2.2475e-01, -2.5939e-01, -1.3468e-01],\n",
      "          [-5.2222e-02, -2.0213e-01, -1.9935e-01, -1.1980e-01, -1.3792e-01]],\n",
      "\n",
      "         [[-2.0106e-01, -2.3014e-01,  1.7406e-01, -3.0948e-01, -2.2481e-01],\n",
      "          [-2.5907e-01, -3.6306e-01, -7.0584e-02, -3.8664e-02, -7.3622e-02],\n",
      "          [-5.5295e-04, -9.3178e-03, -1.4460e-01, -2.5755e-01,  1.3643e-01],\n",
      "          [-3.3538e-01, -2.8258e-01, -2.9659e-01, -3.2681e-02,  5.0230e-02],\n",
      "          [-2.4200e-01, -2.9351e-01, -4.5270e-02, -1.0303e-01, -5.4305e-02]],\n",
      "\n",
      "         [[-1.4726e-01, -1.5361e-01, -8.5093e-02,  3.6908e-02, -1.9852e-01],\n",
      "          [ 9.7890e-02, -3.1569e-01, -1.9606e-01,  1.4336e-02,  1.8620e-01],\n",
      "          [ 5.3358e-02, -9.9861e-02, -1.8681e-01, -7.7977e-02,  8.5808e-02],\n",
      "          [-1.7410e-01, -3.0771e-01, -2.3358e-01, -1.1972e-01, -7.0113e-02],\n",
      "          [-8.7753e-02, -1.8677e-01, -6.7075e-02, -1.1514e-01, -6.2388e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.1773e-02, -1.1378e-01, -5.1954e-01, -4.9517e-01, -1.8426e-01],\n",
      "          [ 4.8771e-02,  1.1191e-02, -6.3010e-01,  2.5563e-01,  1.4445e-01],\n",
      "          [-2.7949e-01, -3.9408e-01, -7.9069e-01, -2.2047e-01,  3.5117e-01],\n",
      "          [-6.1802e-01, -1.1256e+00,  3.2210e-01,  2.2111e-01,  2.2464e-01],\n",
      "          [-4.6832e-01, -2.7233e-01,  3.3016e-01,  4.7011e-02, -3.7041e-02]],\n",
      "\n",
      "         [[-3.9050e-01,  5.4799e-02,  6.8108e-02, -3.3220e-01,  4.5518e-01],\n",
      "          [-1.6066e-01,  1.1741e-01, -5.1165e-01,  3.8380e-03, -4.1624e-01],\n",
      "          [-3.5702e-01, -3.5680e-01, -7.7867e-01,  2.8379e-01,  1.4306e-01],\n",
      "          [-8.9845e-01, -1.4941e+00,  3.9535e-01,  4.9176e-01,  4.5512e-01],\n",
      "          [-1.4408e-01, -2.7532e-03,  3.8961e-01, -2.6000e-03, -2.3903e-01]],\n",
      "\n",
      "         [[ 4.0849e-01,  3.6061e-03, -1.3072e-01, -7.3406e-01, -1.9724e+00],\n",
      "          [ 3.4490e-01, -6.9204e-02,  4.3685e-01,  1.9887e-01, -7.2612e-01],\n",
      "          [ 1.8899e-01,  2.0495e-01,  4.7401e-01, -2.5392e-01, -8.0058e-01],\n",
      "          [ 3.6141e-01,  4.8413e-01,  2.9348e-01, -1.3195e+00, -4.6832e-01],\n",
      "          [ 1.7528e-01, -9.9978e-02, -7.8413e-01, -7.7750e-01, -4.6293e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8430e-01, -4.8388e-01,  8.4580e-01,  2.1235e-01,  1.4575e-01],\n",
      "          [-5.8551e-01, -2.6255e-01,  3.1122e-02, -5.1002e-01, -7.5675e-01],\n",
      "          [-3.4337e-01, -4.9134e-01, -9.3698e-01,  8.0605e-01, -7.1628e-02],\n",
      "          [ 1.8647e-01, -4.0704e-01, -6.7671e-01,  4.6948e-01,  5.7379e-01],\n",
      "          [-4.8998e-01, -6.3543e-02,  1.4531e-01, -3.0847e-01, -6.0494e-01]],\n",
      "\n",
      "         [[ 2.9661e-01, -1.5489e-01, -6.8282e-01,  3.9421e-01,  8.0305e-01],\n",
      "          [-3.6344e-01, -2.8694e-01, -5.9018e-01,  4.7983e-02,  1.0605e+00],\n",
      "          [-7.4787e-01, -4.8183e-01,  1.7121e-01, -6.1648e-01,  3.3303e-02],\n",
      "          [ 9.2293e-03, -2.3891e-01, -7.1119e-02, -7.4026e-01,  4.1982e-02],\n",
      "          [-3.2413e-02, -3.2916e-01, -4.0365e-01,  1.3166e-01,  5.8753e-01]],\n",
      "\n",
      "         [[-2.3320e-01,  2.7380e-01, -1.1042e-01,  2.6057e-01,  1.1595e+00],\n",
      "          [-1.3080e-01,  7.9067e-02,  4.3395e-01, -5.6662e-01,  4.0129e-01],\n",
      "          [-1.8489e-01, -7.3782e-01, -4.1764e-01, -8.7398e-01, -1.5895e+00],\n",
      "          [-3.5869e-01, -8.0583e-01,  2.7625e-02,  1.4849e-01, -1.1245e+00],\n",
      "          [-9.2822e-01, -2.0049e-01, -3.7598e-01, -4.4219e-01, -2.4524e-01]]]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "conv2.bias\n",
      "Parameter containing:\n",
      "tensor([-0.2181, -0.0050, -0.3927, -0.2831, -0.0816, -0.2744, -0.3630, -0.0610,\n",
      "        -0.1083, -0.1154, -0.2330, -0.0035, -0.2043, -0.3459, -0.5046, -0.1287,\n",
      "        -0.4423, -0.1792, -0.2933, -0.8078], device='mps:0',\n",
      "       requires_grad=True)\n",
      "fc1.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0639, -0.0030, -0.0545,  ..., -0.0039, -0.0214,  0.0033],\n",
      "        [-0.0349, -0.0146, -0.0027,  ...,  0.0106, -0.0166,  0.0076],\n",
      "        [-0.0591, -0.0501, -0.0151,  ..., -0.0373,  0.0059, -0.0204],\n",
      "        ...,\n",
      "        [ 0.2318, -0.1669,  0.3645,  ...,  0.6600,  0.5634, -0.0766],\n",
      "        [-0.0377, -0.0375, -0.0183,  ..., -0.0329,  0.0029,  0.0562],\n",
      "        [ 0.3285, -0.6029, -0.7218,  ..., -0.5720, -0.7602,  0.0045]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "fc1.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0055, -0.0579, -0.0014, -0.0347, -0.3050, -0.5241, -0.0258, -0.2854,\n",
      "         0.1819, -0.2374, -0.1113, -0.0532,  0.3454, -0.1721, -0.3697,  0.1181,\n",
      "        -0.0444,  0.2542, -0.0515, -0.4712,  0.0112, -0.2154,  0.6321, -0.0527,\n",
      "        -0.0263,  0.0296, -0.1168,  0.1104, -0.1253, -0.4709, -0.0620,  0.0528,\n",
      "        -0.0155,  0.0095, -0.0046, -0.0485, -0.0400,  0.0587, -0.0177,  0.0368,\n",
      "        -0.0529, -0.0586, -0.2337, -0.0297, -0.2349, -0.3752, -0.0237, -0.2718,\n",
      "        -0.0898, -0.1519], device='mps:0', requires_grad=True)\n",
      "out.weight\n",
      "Parameter containing:\n",
      "tensor([[-5.4965e-02, -1.0804e-01,  8.3917e-02, -1.3745e-01,  2.0267e-01,\n",
      "         -1.9485e-01,  1.0662e-01,  1.5297e-01,  3.1995e-01, -3.3190e-01,\n",
      "         -1.0341e-01, -1.6448e-01, -4.4308e-01, -3.8802e-01, -1.4680e-01,\n",
      "          1.8435e-01,  2.0179e-02, -2.3703e-01,  6.7002e-02, -2.4952e-03,\n",
      "         -1.4765e-02, -3.2439e-01, -5.0303e-01, -6.0120e-02, -1.7359e-01,\n",
      "         -3.7020e-01,  6.9283e-03, -2.1425e-01, -8.1155e-02, -2.6985e-01,\n",
      "         -1.0868e-01,  7.5768e-02, -7.8216e-02, -1.3554e-01, -1.0038e-03,\n",
      "          7.1366e-02,  8.3686e-02,  4.1883e-01, -2.3022e-02, -5.4327e-01,\n",
      "          3.8567e-02,  1.0366e-01, -3.3842e-01, -1.4149e-01,  4.0945e-01,\n",
      "         -1.5464e-01, -2.8928e-01,  1.7677e-01,  6.4193e-02, -2.0182e-01],\n",
      "        [-3.8571e-02, -1.5924e-01, -2.2964e-02,  1.0830e-01, -1.0260e-01,\n",
      "         -3.7348e-01, -4.1368e-02, -3.1717e-01,  2.8836e-01, -3.9630e-01,\n",
      "          2.8090e-01, -3.7771e-02,  6.4818e-02, -4.1361e-01, -2.0240e-01,\n",
      "          2.1228e-01, -1.2021e-01,  3.4316e-02,  4.7289e-02, -2.1418e-01,\n",
      "         -1.1467e-01, -1.7816e-01,  1.7918e-01,  4.2334e-02, -2.3957e-02,\n",
      "          5.7954e-01,  2.0890e-01, -2.2944e-01, -3.8152e-02,  1.7215e-02,\n",
      "         -4.6193e-02, -8.0356e-02,  5.0644e-02,  8.0268e-02,  2.5937e-02,\n",
      "         -1.2016e-02, -1.5769e-01, -1.6637e-01, -8.6067e-02,  1.1463e-01,\n",
      "         -3.3023e-01, -5.6584e-02, -1.8435e-01, -8.1628e-02, -4.3475e-01,\n",
      "         -4.0471e-01, -3.9780e-01, -2.0104e-01,  2.8971e-02,  5.2300e-02],\n",
      "        [ 1.6931e-02,  1.2623e-01, -2.0249e-02, -1.4546e-01, -1.1161e-01,\n",
      "          1.3503e-01, -1.5111e-01,  1.4254e-01,  2.0272e-01, -2.8299e-01,\n",
      "         -1.0485e-01,  8.8049e-02, -3.2240e-01,  1.4102e-01, -2.2185e-01,\n",
      "         -1.9285e-01,  7.4074e-02, -3.0689e-01,  2.6262e-02, -5.3174e-01,\n",
      "         -2.6301e-03, -1.4250e-01,  1.5342e-01, -7.2188e-02, -1.6422e-01,\n",
      "          8.5440e-02, -1.5885e-01,  2.1884e-01, -1.8694e-02, -1.2107e-01,\n",
      "          4.1907e-02, -2.1264e-01, -1.1085e-01,  9.4285e-03, -7.3980e-02,\n",
      "         -1.6312e-01,  3.1012e-02, -1.9185e-01, -8.9295e-02, -1.4481e-02,\n",
      "         -1.0227e-01, -2.3888e-02,  3.6772e-01,  3.6775e-02, -4.9656e-01,\n",
      "          3.7543e-01, -3.0089e-01,  3.4414e-01,  3.9001e-03, -6.7797e-01],\n",
      "        [-3.0804e-03,  5.7265e-02, -4.0954e-02,  1.0193e-01, -2.4613e-01,\n",
      "         -3.2147e-01,  7.8906e-02, -1.9168e-01, -3.9293e-01,  2.9540e-01,\n",
      "          2.2003e-01, -6.3691e-02, -5.0711e-01,  4.0826e-01, -2.8360e-01,\n",
      "         -4.9945e-01, -1.1518e-02, -5.3742e-02, -8.0898e-02,  1.1203e-02,\n",
      "         -7.1637e-02,  1.7110e-01,  2.0191e-01, -1.2191e-01, -2.4517e-02,\n",
      "         -2.3450e-01, -1.4549e-02,  1.9419e-01, -5.2883e-02, -3.8374e-02,\n",
      "          3.0604e-02,  4.2922e-01, -1.2736e-01,  1.5562e-02, -1.5483e-01,\n",
      "         -6.2973e-02,  4.6532e-02, -2.7449e-01,  2.5843e-02,  9.0430e-03,\n",
      "          3.9346e-01,  6.6902e-02,  1.7392e-01, -1.1087e-01, -3.5004e-01,\n",
      "         -3.9972e-02, -3.3604e-01, -1.6009e-01, -4.1745e-02, -2.8669e-01],\n",
      "        [-6.1230e-02,  4.7371e-03, -1.1126e-02, -9.3837e-02,  2.2650e-02,\n",
      "         -5.6812e-02, -4.8674e-02, -2.5047e-01, -6.9871e-01, -3.9114e-01,\n",
      "          1.7617e-01, -6.3688e-02,  2.3155e-01,  7.8648e-02,  4.3799e-02,\n",
      "          5.5016e-01,  1.0570e-01, -2.2688e-01,  3.4994e-02, -6.2473e-01,\n",
      "         -6.8242e-02,  3.3823e-01, -4.5263e-01,  4.3241e-02, -3.8733e-02,\n",
      "         -4.4717e-02, -8.2305e-02, -4.0575e-01,  2.0525e-02, -3.1528e-01,\n",
      "         -4.9600e-02, -3.8094e-01,  1.2077e-01,  3.4856e-02,  7.5159e-03,\n",
      "         -7.1160e-02, -9.2253e-02, -6.1267e-01,  5.1308e-02,  4.7276e-02,\n",
      "         -6.8494e-01,  2.8173e-02, -6.4514e-01,  3.4800e-02,  5.9058e-02,\n",
      "          3.0613e-01,  2.4415e-01,  1.3578e-01,  1.4363e-01, -2.7638e-01],\n",
      "        [ 2.9398e-03, -1.0502e-01, -2.0151e-02, -4.8688e-02,  2.6589e-01,\n",
      "         -2.3057e-01, -1.1286e-01, -4.3149e-01, -1.2307e-01,  5.0848e-02,\n",
      "         -7.9194e-02,  8.0897e-02, -4.6368e-01, -3.0146e-01,  2.1966e-01,\n",
      "         -5.9558e-01, -4.1046e-03, -1.2963e-01, -5.4203e-02,  4.0414e-01,\n",
      "          1.4490e-01,  1.2447e-01, -3.1625e-02,  4.9977e-02, -1.2902e-01,\n",
      "         -4.1578e-01,  3.7377e-01,  2.4334e-01, -6.8666e-02,  2.0998e-01,\n",
      "         -5.7742e-03, -1.5751e-01, -1.0320e-01, -3.1633e-02, -1.0698e-01,\n",
      "         -6.3643e-02, -8.8763e-02, -5.0847e-01, -1.0191e-01, -4.2608e-01,\n",
      "         -1.1127e-01,  9.4714e-02, -1.5998e-01, -4.0841e-02, -6.1662e-01,\n",
      "          1.4152e-01, -1.7883e-01, -3.0341e-01, -5.3264e-03,  1.6585e-01],\n",
      "        [-1.3788e-01, -3.5225e-02, -2.2234e-02,  9.1939e-02,  1.3859e-01,\n",
      "         -3.2372e-01, -5.5816e-02, -4.5194e-01, -3.1916e-01, -5.8497e-01,\n",
      "         -2.1346e-01, -3.9349e-02, -4.5223e-01, -1.1021e-01, -2.4870e-01,\n",
      "         -1.7670e-01,  1.0013e-01,  1.8216e-01, -5.4139e-02,  2.0672e-01,\n",
      "          4.2448e-02, -4.4661e-01, -4.7010e-01, -7.7581e-02,  4.2299e-02,\n",
      "          2.4272e-01, -1.0528e-01, -1.4691e-01,  1.7860e-02, -1.2764e-02,\n",
      "         -1.1781e-01, -4.6831e-01, -5.4423e-02, -1.5478e-01,  1.3505e-01,\n",
      "         -1.1142e-01, -1.1362e-01, -4.1185e-01, -8.4294e-02, -5.6933e-01,\n",
      "         -3.5064e-01,  4.5196e-02, -2.1650e-01, -1.6144e-01,  3.6085e-01,\n",
      "          3.1830e-01,  1.9087e-01, -2.8671e-01,  3.1392e-02,  2.5019e-01],\n",
      "        [-6.7391e-02,  4.1093e-02, -1.0518e-01,  1.0417e-02, -1.0657e-01,\n",
      "         -2.3783e-01,  1.4215e-01, -2.4645e-02,  1.6892e-01,  2.8689e-01,\n",
      "         -5.2355e-01,  3.1730e-02,  3.8385e-01,  2.4037e-01, -3.2449e-01,\n",
      "         -5.0464e-01,  4.4482e-02, -4.0692e-01,  8.5380e-02, -4.2319e-01,\n",
      "          1.0313e-01,  1.9759e-01,  1.2419e-02,  5.8224e-02, -3.0673e-02,\n",
      "         -3.1646e-01,  2.0323e-02,  1.7088e-01, -1.3543e-01, -2.5588e-02,\n",
      "         -1.5302e-01, -4.3132e-01,  1.0387e-02, -3.0548e-02,  2.9843e-02,\n",
      "         -7.9241e-02, -5.9863e-02,  1.3636e-01,  4.6092e-02,  3.4005e-01,\n",
      "         -3.6691e-02, -9.4404e-03,  4.0679e-02, -9.0979e-02, -4.0243e-01,\n",
      "         -1.5454e-01, -4.8311e-01, -3.2353e-01, -4.1747e-02, -7.2108e-01],\n",
      "        [-8.0746e-02,  2.1323e-02, -8.7119e-02,  8.1493e-02, -2.2255e-02,\n",
      "         -6.4054e-01, -1.0877e-01,  3.1194e-01, -3.0251e-01,  8.9339e-03,\n",
      "          9.6006e-03, -1.2862e-01, -1.8247e-02, -1.9971e-01, -2.2375e-01,\n",
      "         -2.8268e-01, -4.2757e-02,  4.1325e-01,  7.5754e-02, -5.6399e-02,\n",
      "         -6.6067e-02, -5.8107e-01,  2.1761e-01, -1.4724e-02, -4.0595e-02,\n",
      "         -3.2000e-01, -1.3715e-01,  1.4116e-01,  1.6414e-01,  2.4174e-01,\n",
      "         -2.6487e-02, -1.6340e-01, -8.5702e-02, -2.9234e-02, -1.0630e-01,\n",
      "         -4.2302e-02, -1.0554e-02, -9.9164e-02,  1.4456e-02, -4.1355e-01,\n",
      "         -7.3809e-02, -5.5708e-03, -2.7406e-01,  1.0769e-01, -4.7081e-01,\n",
      "         -2.0712e-01,  3.3432e-01, -4.9262e-01, -1.1518e-01,  2.2142e-01],\n",
      "        [ 4.5162e-02, -1.5565e-01,  1.7499e-01,  1.8704e-02, -1.7711e-01,\n",
      "         -4.1711e-01, -1.0501e-01,  1.4155e-01, -8.2705e-02,  3.0154e-01,\n",
      "         -6.0531e-02, -1.4439e-01,  5.9439e-02, -2.3142e-01,  4.4965e-01,\n",
      "          3.7845e-02,  4.7508e-03, -4.5156e-01,  3.4467e-02, -4.5389e-01,\n",
      "          4.8298e-02,  6.3472e-02, -5.0022e-01,  1.0749e-01,  4.6013e-02,\n",
      "         -4.1568e-01, -5.3421e-02, -6.4737e-01, -8.4042e-02, -4.4605e-02,\n",
      "          9.5146e-02,  2.6889e-02, -7.7076e-02,  9.9968e-02,  8.4410e-02,\n",
      "         -2.3767e-02, -9.5278e-02,  1.6749e-01, -1.1645e-01,  1.2947e-01,\n",
      "         -2.0359e-01, -1.2857e-01, -1.6121e-01, -1.6541e-01, -3.1802e-01,\n",
      "         -4.9888e-01,  2.2455e-01,  1.6121e-01, -1.0547e-01,  4.5047e-04]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "out.bias\n",
      "Parameter containing:\n",
      "tensor([-0.1526,  0.4971, -0.2885,  0.2021, -0.0467, -0.1145, -0.8675,  0.0789,\n",
      "         0.3856, -0.0207], device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)   # e.g., 'fc1.weight'\n",
    "    print(param)  # the actual tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4fb8bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the target model\n",
    "fmnist_model , f_loss_fun , f_optimizer = createMnisNet()\n",
    "\n",
    "# replace all weights in a Target model from source model\n",
    "for target,source in zip(fmnist_model.named_parameters(),model.named_parameters()):\n",
    "    target[1].data = copy.deepcopy(source[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af5b8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.6434, Train Acc: 77.13, Test Acc: 78.44\n",
      "Epoch 2/5, Train Loss: 0.4815, Train Acc: 82.81, Test Acc: 83.64\n",
      "Epoch 3/5, Train Loss: 0.4385, Train Acc: 84.19, Test Acc: 85.22\n",
      "Epoch 4/5, Train Loss: 0.4071, Train Acc: 85.41, Test Acc: 84.72\n",
      "Epoch 5/5, Train Loss: 0.3880, Train Acc: 86.01, Test Acc: 84.77\n"
     ]
    }
   ],
   "source": [
    "losses, train_accuracy, test_accuracy = trainTheM0del(\n",
    "        isClassification=True,\n",
    "        optimizer = optimizer,\n",
    "        doBN=False,\n",
    "        model=model,\n",
    "        train_loader=fmnist_train_loader,   \n",
    "        test_loader=fmnist_test_loader,\n",
    "        num_epochs=5, \n",
    "        loss_function= lossfun,\n",
    "        device = device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9c9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
