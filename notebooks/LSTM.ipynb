{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3c7edc",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0487cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5e9c8",
   "metadata": {},
   "source": [
    "# Explore LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "60d33e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(9, 16, num_layers=2, batch_first=True)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 9\n",
    "hidden_size = 16\n",
    "num_layers = 2\n",
    "lstm = nn.LSTM(input_size, hidden_size, num_layers,batch_first=True)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "052ef8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 8, 9]),\n",
       " torch.Size([3, 8, 16]),\n",
       " torch.Size([2, 3, 16]),\n",
       " torch.Size([2, 3, 16]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "sequence_length = 8\n",
    "\n",
    "X = torch.randn(batch_size,sequence_length,input_size)\n",
    "\n",
    "H = torch.randn(num_layers,batch_size,hidden_size) # cell state\n",
    "C = torch.randn(num_layers,batch_size,hidden_size) # hidden state\n",
    "\n",
    "hidden_input = (H,C)\n",
    "\n",
    "out, (h,c) = lstm(X,hidden_input)\n",
    "X.shape , out.shape, h.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ccaccfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1325, -0.1257, -0.2387,  0.1612, -0.0332,  0.0516,  0.2478,  0.0851,\n",
       "         0.0167, -0.1328, -0.1525,  0.2975, -0.1094, -0.1648,  0.0196,  0.1214],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0,0,:] # hidden state of first layer , first batch and all time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "af4ec585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0: torch.Size([64, 9])\n",
      "weight_hh_l0: torch.Size([64, 16])\n",
      "weight_ih_l1: torch.Size([64, 16])\n",
      "weight_hh_l1: torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "for p in lstm.named_parameters():\n",
    "    if 'weight' in p[0]:\n",
    "        print(f'{p[0]}: {p[1].shape}') # 64 cames from 16*4 where 4 is the number of gates and 16 is the hidden size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae1476d",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a736488",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer volutpat bibendum risus id molestie. Integer sit amet arcu vitae leo maximus convallis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean eu dui feugiat, interdum metus eget, tempor ante. Maecenas luctus enim nec diam pellentesque rhoncus. Suspendisse vestibulum suscipit ultrices. Sed at gravida enim. Integer laoreet risus risus, ac semper sem feugiat ut. Mauris et massa ipsum.' \\\n",
    "'Sed laoreet eget ipsum efficitur venenatis. Aenean cursus porttitor suscipit. Etiam hendrerit leo consequat nulla egestas, nec tristique diam mattis. Morbi fermentum elementum nisl, id porta lorem luctus posuere. Etiam dapibus lacus sed mauris molestie, eget lacinia lacus lobortis. Etiam imperdiet vitae ante eget vestibulum. Duis purus sapien, accumsan eu sollicitudin at, faucibus eget lacus. Maecenas sit amet risus faucibus, pulvinar elit quis, iaculis erat. Vivamus condimentum volutpat orci at bibendum. Duis ut convallis magna, ut pretium ipsum. Aenean feugiat varius dui ut luctus. Pellentesque eros massa, pharetra et purus quis, ullamcorper volutpat justo. Ut nec enim eu ante pulvinar hendrerit vitae imperdiet leo.' \\\n",
    "'Nullam et nibh et purus faucibus fermentum. Nunc cursus maximus lacus, pretium congue tellus bibendum id. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc interdum lacus ac lacus malesuada scelerisque. Mauris urna risus, lacinia at est sed, pulvinar varius sem. Aenean enim nisi, condimentum eleifend finibus non, vehicula eu nibh. Donec pretium ligula purus, eu commodo risus iaculis eu. Fusce vehicula dolor eget rhoncus auctor. Ut iaculis, sem a faucibus dignissim, odio magna scelerisque nulla, a pulvinar mi lectus quis ante. Vestibulum sem enim, ullamcorper non augue sodales, fermentum dignissim augue. Phasellus vitae mollis ipsum, a sodales nunc. In tempor sagittis risus vitae ornare. Etiam tristique tellus vehicula, iaculis quam sed, facilisis nunc. Nunc suscipit nisi eu suscipit viverra. Interdum et malesuada fames ac ante ipsum primis in faucibus.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "576b0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer volutpat bibendum risus id molestie. Integer sit amet arcu vitae leo maximus convallis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean eu dui feugiat, interdum metus eget, tempor ante. Maecenas luctus enim nec diam pellentesque rhoncus. Suspendisse vestibulum suscipit ultrices. Sed at gravida enim. Integer laoreet risus risus, ac semper sem feugiat ut. Mauris et massa ipsum.Sed laoreet eget ipsum efficitur venenatis. Aenean cursus porttitor suscipit. Etiam hendrerit leo consequat nulla egestas, nec tristique diam mattis. Morbi fermentum elementum nisl, id porta lorem luctus posuere. Etiam dapibus lacus sed mauris molestie, eget lacinia lacus lobortis. Etiam imperdiet vitae ante eget vestibulum. Duis purus sapien, accumsan eu sollicitudin at, faucibus eget lacus. Maecenas sit amet risus faucibus, pulvinar elit quis, iaculis erat. Vivamus condimentum volutpat orci at bibendum. Duis ut convallis magna, ut pretium ipsum. Aenean feugiat varius dui ut luctus. Pellentesque eros massa, pharetra et purus quis, ullamcorper volutpat justo. Ut nec enim eu ante pulvinar hendrerit vitae imperdiet leo.Nullam et nibh et purus faucibus fermentum. Nunc cursus maximus lacus, pretium congue tellus bibendum id. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc interdum lacus ac lacus malesuada scelerisque. Mauris urna risus, lacinia at est sed, pulvinar varius sem. Aenean enim nisi, condimentum eleifend finibus non, vehicula eu nibh. Donec pretium ligula purus, eu commodo risus iaculis eu. Fusce vehicula dolor eget rhoncus auctor. Ut iaculis, sem a faucibus dignissim, odio magna scelerisque nulla, a pulvinar mi lectus quis ante. Vestibulum sem enim, ullamcorper non augue sodales, fermentum dignissim augue. Phasellus vitae mollis ipsum, a sodales nunc. In tempor sagittis risus vitae ornare. Etiam tristique tellus vehicula, iaculis quam sed, facilisis nunc. Nunc suscipit nisi eu suscipit viverra. Interdum et malesuada fames ac ante ipsum primis in faucibus.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dfa3e3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = set(text.lower())\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2ac70d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': 0,\n",
       " 'c': 1,\n",
       " ' ': 2,\n",
       " 'u': 3,\n",
       " 'v': 4,\n",
       " 'a': 5,\n",
       " 's': 6,\n",
       " 'g': 7,\n",
       " 'f': 8,\n",
       " 'i': 9,\n",
       " 'e': 10,\n",
       " 'l': 11,\n",
       " 'n': 12,\n",
       " 'h': 13,\n",
       " 'r': 14,\n",
       " '.': 15,\n",
       " 'j': 16,\n",
       " 'o': 17,\n",
       " 'd': 18,\n",
       " ',': 19,\n",
       " 'x': 20,\n",
       " 'p': 21,\n",
       " 'b': 22,\n",
       " 'q': 23,\n",
       " 'm': 24}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet_map = {c:i for i,c in enumerate(alphabet)}\n",
    "alphabet_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "01112557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11],\n",
       "        [17],\n",
       "        [14],\n",
       "        ...,\n",
       "        [ 3],\n",
       "        [ 6],\n",
       "        [15]], device='mps:0')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "data = torch.zeros((len(text),1),dtype=torch.int64,device=device)\n",
    "\n",
    "for i,c in enumerate(text.lower()):\n",
    "    data[i,0] = alphabet_map[c]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5ccdaf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size,embedding_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "       \n",
    "        \n",
    "    def forward(self, x,h=None):\n",
    "       \n",
    "        embedding = self.embedding(x)\n",
    "        out,hidden  = self.lstm(embedding,h) \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[-1])\n",
    "        return out,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "89fed481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(25, 64)\n",
       "  (lstm): LSTM(64, 512, num_layers=3)\n",
       "  (fc): Linear(in_features=512, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 512\n",
    "num_layers = 3\n",
    "sequence_length = 80\n",
    "embedding_size = 64\n",
    "input_size = len(alphabet)\n",
    "\n",
    "model = LSTMModel(len(alphabet),embedding_size, hidden_size, num_layers, len(alphabet)).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5bf2c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "620645b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3], device='mps:0')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset = 0\n",
    "x = data[offset:offset+sequence_length]\n",
    "y = data[offset+sequence_length]\n",
    "x.shape , y.shape\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "398a8891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(x)\n",
    "pred[0].shape # since we have 80 time step, we need only the last one to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2de7cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLSTM(model,data,lossFun,optimizer,epochs):\n",
    "    losses = np.zeros(epochs)\n",
    "    accuracy = np.zeros(epochs)\n",
    "    for epoch in range(epochs):\n",
    "        txtLoss = []\n",
    "        txtAcc = []\n",
    "\n",
    "        for offset in range(len(data)-sequence_length):\n",
    "            x = data[offset:offset+sequence_length].to(device)\n",
    "            y = data[offset+sequence_length].to(device)\n",
    "            pred = model(x)[0]\n",
    "            loss = lossFun(pred,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            txtLoss.append(loss.item())\n",
    "            acc = (torch.argmax(pred,dim=1) == y).float()\n",
    "            txtAcc.append(acc.item())\n",
    "\n",
    "        accuracy[epoch] = np.mean(txtAcc)\n",
    "        losses[epoch] = np.mean(txtLoss)\n",
    "        print(f'Loss {epoch+1}/{epochs}: {losses[epoch]} Accuracy {epoch+1}/{epochs}: {accuracy[epoch]}')    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b9074f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1/10: 2.6824845738312386 Accuracy 1/10: 0.18920282542885974\n",
      "Loss 2/10: 2.291729949234527 Accuracy 2/10: 0.2815338042381433\n",
      "Loss 3/10: 2.0235883114818582 Accuracy 3/10: 0.3521695257315843\n",
      "Loss 4/10: 1.744490340944355 Accuracy 4/10: 0.43693239152371344\n",
      "Loss 5/10: 1.3967397079701318 Accuracy 5/10: 0.5332996972754793\n",
      "Loss 6/10: 1.0752430218155027 Accuracy 6/10: 0.641271442986882\n",
      "Loss 7/10: 0.7934677864220305 Accuracy 7/10: 0.7346115035317861\n",
      "Loss 8/10: 0.6053192191701051 Accuracy 8/10: 0.7936427850655903\n",
      "Loss 9/10: 0.4393341816199679 Accuracy 9/10: 0.8541876892028254\n",
      "Loss 10/10: 0.36431626299200937 Accuracy 10/10: 0.8859737638748738\n"
     ]
    }
   ],
   "source": [
    "trainLSTM(model,data,lossFun,optimizer,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "edc2db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number2char = {v:k for k,v in alphabet_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5d0f00f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lorem ipsum dolor sit amet, consectetur adipiscing elit. integer volutpat bibend'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ''\n",
    "for l in x:\n",
    "    t+=number2char[l.item()]\n",
    "t    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016df45c",
   "metadata": {},
   "source": [
    "# Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "49dff6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bi at bibendum risus id molestie, interdum et malesuada fames ac ante ipsum primis in faucibus quis sit amet, facilisis nunc. nunc suscipit viverra. irterdum et malesuada fames ac ante ipsum primis in faucibus quis sit amet, facilisis nunc. nunc suscipit viverra. irterdum et malesuada fames ac ante i'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_length =300\n",
    "hidden = None\n",
    "\n",
    "\n",
    "first_letter = torch.tensor(alphabet_map['b']).reshape(1,1).to(device)\n",
    "\n",
    "generated_txt = number2char[first_letter.item()]\n",
    "for i in range(generated_length):\n",
    "    pred,hidden = model(first_letter,hidden)\n",
    "    pred = torch.argmax(pred,dim=1)\n",
    "    first_letter = pred.reshape(1,1)\n",
    "    char = number2char[pred.item()]\n",
    "    generated_txt += char\n",
    "generated_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5bb92342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proin interdum, nisi in tempor mollis, risus erat condimentum'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = 'Proin interdum, nisi in tempor mollis, risus erat condimentum ipsum, id fringilla elit est ut massa. Donec at auctor ipsum, eget laoreet risus. Donec nisi sapien, euismod id massa id, accumsan accumsan ex. Nulla facilisi. Ut vulputate lacus libero, in tristique nisl viverra id. Nunc euismod tincidunt odio. Quisque gravida id est eget venenatis.'.lower()\n",
    "part_test = test_text[:61]\n",
    "part_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8beeb1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proin interdum, nisi in tempor mollis, risus erat condimentum dignissim augue. phasellus vehicula, iaculis quam sed, facilisis nunc. nunc suscipit viverra. irterdum et malesuada fames ac ante ipsum primis in faucibus quis sit amet, facilisis nunc. nunc suscipit viverra. irterdum et malesuada fames ac ante ipsum primis in faucibus quis sit amet, facilisis nunc.'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_test_tensor = torch.zeros((len(part_test),1),dtype=torch.int64,device=device)\n",
    "\n",
    "for i,c in enumerate(part_test.lower()):\n",
    "    part_test_tensor[i,0] = alphabet_map[c]\n",
    "\n",
    "hidden = None\n",
    "\n",
    "pred,hidden = model(part_test_tensor,hidden)\n",
    "pred = torch.argmax(pred,dim=1)\n",
    "first_letter = pred.reshape(1,1)\n",
    "char = number2char[pred.item()]\n",
    "part_test += char\n",
    "\n",
    "for i in range(generated_length):\n",
    "    pred,hidden = model(first_letter,hidden)\n",
    "    pred = torch.argmax(pred,dim=1)\n",
    "    first_letter = pred.reshape(1,1)\n",
    "    char = number2char[pred.item()]\n",
    "    part_test += char\n",
    "part_test  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
