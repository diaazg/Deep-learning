{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# convolution function\n",
    "from scipy.signal import convolve2d\n",
    "#  to read image from url\n",
    "from imageio import imread\n",
    "# to display image\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# some info about the model \n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.transforms as T # provides all the transformations of images\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of layers in CNN \n",
    "\n",
    " - **Convolutional Layer**: Applies a filter to the input to produce a feature map.\n",
    "\n",
    " - **Pooling Layer**: Reduces the size of the feature map  and increase receptive field by applying a pooling operation.\n",
    "\n",
    " - **Fully Connected Layer**: Prediction (categorical and/or regression).\n",
    "\n",
    "\n",
    "- With increasing depth : \n",
    "\n",
    " - Image resolution (number of pixels) decreases.\n",
    "\n",
    " - Representation resolution (number of filters) increases.\n",
    "\n",
    " - Layers are smaller(number of pixels) but wider (number of feature maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN architecture**\n",
    "\n",
    "![mnistCnn](./assets/cnnMnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/mnist_train.csv')\n",
    "df_test = pd.read_csv('../data/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_train.values[:, 1:]\n",
    "labels = df_train.values[:, 0]\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNorm = data / np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataNorm = dataNorm.reshape(dataNorm.shape[0], 1, 28, 28)\n",
    "dataNorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = torch.tensor(dataNorm, dtype=torch.float32)\n",
    "labelsT = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data , train_labels, test_labels = train_test_split(dataT, labelsT, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data = TensorDataset(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36000, 1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28224000\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset.tensors[0].shape.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMnisNet(printtogle=False):\n",
    "    class MNISnet(nn.Module):\n",
    "        def __init__(self,printtogle):\n",
    "            super().__init__()\n",
    "             \n",
    "             # convolutional layers\n",
    "\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1, padding=1)\n",
    "            # out_channels represents the number of feature maps\n",
    "            # the output will be np.floor((28-5+2*1)/1) + 1 = 26 \n",
    "            # then we apply max pooling by spatial extent 2*2 so the output will be 26/2 = 13 \n",
    "            self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=1) \n",
    "            # output will be 13-5+2*1 = 11\n",
    "            # then we apply max pooling by spatial extent 2*2 so the output will be 11/2 = 5\n",
    "            # in this case we take the floor so the ceiling mode in the max pooling will be False since it give 5 not 6\n",
    "            \n",
    "            # Computer number of units in FC layer (number of output of conv2)\n",
    "            expectSize = np.floor((5+2*0-1)/1) + 1\n",
    "            expectSize = 20*int(expectSize**2)\n",
    "\n",
    "            ### fully connected layer\n",
    "            self.fc1 = nn.Linear(expectSize, 50)\n",
    "            self.out = nn.Linear(50, 10)\n",
    "            # togle for printing out our tensorsizes during forward pass\n",
    "            self.print = printtogle\n",
    "\n",
    "        def forward(self, x,doBN=False):\n",
    "            print(f'Input: {x.shape} ') if self.print else None\n",
    "\n",
    "            # convol -> maxpool -> relu\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "            print(f'Conv1/pool1: {x.shape} ') if self.print else None\n",
    "\n",
    "            x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "            print(f'Conv2/pool2: {x.shape} ') if self.print else None\n",
    "\n",
    "            nUnits  = x.shape.numel() / x.shape[0] # number of units \n",
    "            #we get it by dividing the total number of units by the batch size to get the number of units per image\n",
    "            x = x.view(-1,int(nUnits))\n",
    "            # -1 tells pytorch to infer the first dimension\n",
    "            # Reshape x to (batch_size, nUnits)\n",
    "            # we can do that x = x.view(x.shape[0], int(nUnits)) by -1 is automatically and well\n",
    "\n",
    "\n",
    "            print(f'Vectorized: {x.shape} ') if self.print else None\n",
    "\n",
    "            # Linear layers\n",
    "            x = F.relu(self.fc1(x))\n",
    "            print(f'FC1: {x.shape} ') if self.print else None\n",
    "\n",
    "            x = self.out(x)\n",
    "            print(f'Output: {x.shape} ') if self.print else None\n",
    "\n",
    "            return x\n",
    "\n",
    "    net = MNISnet(printtogle)\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=.001)\n",
    "    \n",
    "    \n",
    "    return net, lossfun, optimizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([32, 1, 28, 28]) \n",
      "Conv1/pool1: torch.Size([32, 10, 13, 13]) \n",
      "Conv2/pool2: torch.Size([32, 20, 5, 5]) \n",
      "Vectorized: torch.Size([32, 500]) \n",
      "FC1: torch.Size([32, 50]) \n",
      "Output: torch.Size([32, 10]) \n",
      "torch.Size([32, 10])\n",
      "torch.Size([32])\n",
      "tensor(2.2814, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net, lossfun, optimizer = createMnisNet(printtogle=True)\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "print(yHat.shape)\n",
    "print(y.shape)\n",
    "\n",
    "loss = lossfun(yHat, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([2, 1, 28, 28]) \n",
      "Conv1/pool1: torch.Size([2, 10, 13, 13]) \n",
      "Conv2/pool2: torch.Size([2, 20, 5, 5]) \n",
      "Vectorized: torch.Size([2, 500]) \n",
      "FC1: torch.Size([2, 50]) \n",
      "Output: torch.Size([2, 10]) \n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 26, 26]             260\n",
      "            Conv2d-2           [-1, 20, 11, 11]           5,020\n",
      "            Linear-3                   [-1, 50]          25,050\n",
      "            Linear-4                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 30,840\n",
      "Trainable params: 30,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 0.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../models')\n",
    "import importlib \n",
    "import training\n",
    "importlib.reload(training)\n",
    "from training import trainTheM0del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "model, lossfun, optimizer = createMnisNet(printtogle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.2908, Train Acc: 91.12, Test Acc: 96.75\n",
      "Epoch 2/5, Train Loss: 0.0847, Train Acc: 97.36, Test Acc: 97.76\n",
      "Epoch 3/5, Train Loss: 0.0596, Train Acc: 98.13, Test Acc: 98.03\n",
      "Epoch 4/5, Train Loss: 0.0459, Train Acc: 98.54, Test Acc: 98.37\n",
      "Epoch 5/5, Train Loss: 0.0382, Train Acc: 98.78, Test Acc: 98.52\n"
     ]
    }
   ],
   "source": [
    "losses, train_accuracy, test_accuracy = trainTheM0del(\n",
    "        isClassification=True,\n",
    "        optimizer = optimizer,\n",
    "        doBN=False,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        loss_function= lossfun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
